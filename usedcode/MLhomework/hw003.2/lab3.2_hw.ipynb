{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d05e36-6b0a-4802-8550-450e46c4e734",
   "metadata": {},
   "source": [
    "# 背景概述\n",
    "\n",
    "$\\quad$你是脸盲吗😱? 不管是不是, 都欢迎完成本次上机作业! 我们将构建一个基于支持向量机的人脸识别器, 判定某张人脸图片归属于数据库内的哪个人. 我们将使用[LFW(Labeled Faces in the Wild)数据集](https://vis-www.cs.umass.edu/lfw/), 其中含有若干张人脸图片(RGB三通道彩图)及其对应的人名."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a9e16-039d-4946-b4dd-75f6e37c0aad",
   "metadata": {},
   "source": [
    "# 数据的读取与清洗\n",
    "\n",
    "$\\quad$我们可以利用[`sklearn.datasets`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets)模块的函数[`fetch_lfw_people`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html#sklearn.datasets.fetch_lfw_people)自动在特定的条件要求下进行人脸图片抓取.\n",
    "\n",
    "- **任务1**: 完成函数`process_lfw_data`的编写, 实现数据集的预处理、训练-测试分拆与描述性参数的整理. 输入:\n",
    "  - `lfw_data`, 经过`fetch_lfw_people`函数下载(或加载好)的数据集. 这是一个类似于字典的数据结构, 类属性保存了关于这个数据集的若干描述性信息, 例如`images`、`target`、`target_names`等.\n",
    "  - `test_size`, 测试集大小. 默认值为0.3, 即训练集 : 测试集 = 7 : 3. 进行拆分时, 要求对原数据集做一次随机打乱(`shuffle=True`).\n",
    "  - `random_state`, 用于传入`sklearn`中涉及随机性的函数(例如[`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn-model-selection-train-test-split)), 保证可复现性. 默认值为42.\n",
    "- 返回一个五元元组, 前四个元素分别是拆分好的`X_train`、`X_test`、`y_true_train`、`y_true_test`, 最后一个元素是一个元组, 内容按顺序包括:\n",
    "  - 人脸图片高度`H`;\n",
    "  - 人脸图片宽度`W`;\n",
    "  - 数据集中涵盖了多少人`n_classes`;\n",
    "  - 数据集中涵盖的那些人的名字`target_names`, 要求返回的是一个列表.\n",
    "- 由于`X`的取值区间是`[0, 255)`, 因此要求对`X`进行数据重标度: 各个值除以255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ca3e7-328c-4136-aa8d-79cd7fcd0ae4",
   "metadata": {},
   "source": [
    "### 提示\n",
    "- `fetch_lfw_people`函数默认将RGB三个色彩通道加工处理成单通道的灰度图, 因此不需要担心多个色彩通道的问题.\n",
    "- 由于数据集被施加了若干限制条件(详见下一个代码块), 因此你在编写函数时, 需要访问`lfw_data`对应的类属性, 而不能直接根据官方文档的数字直接抄写."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affc7edc-bad7-4320-ba97-721e9d7b861e",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2fd6fffe5e7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_lfw_people\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlfw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_lfw_people\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_faces_per_person\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\python\\conda\\lib\\site-packages\\sklearn\\datasets\\_lfw.py\u001b[0m in \u001b[0;36mfetch_lfw_people\u001b[1;34m(data_home, funneled, resize, min_faces_per_person, color, slice_, download_if_missing, return_X_y)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \"\"\"\n\u001b[1;32m--> 312\u001b[1;33m     lfw_home, data_folder_path = _check_fetch_lfw(\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[0mdata_home\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_home\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunneled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunneled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_if_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_if_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;32mD:\\python\\conda\\lib\\site-packages\\sklearn\\datasets\\_lfw.py\u001b[0m in \u001b[0;36m_check_fetch_lfw\u001b[1;34m(data_home, funneled, download_if_missing)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdownload_if_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Downloading LFW metadata: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                 \u001b[0m_fetch_remote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlfw_home\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is missing\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtarget_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\conda\\lib\\site-packages\\sklearn\\datasets\\_base.py\u001b[0m in \u001b[0;36m_fetch_remote\u001b[1;34m(remote, dirname)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdirname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m     \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1455\u001b[0m     \u001b[0mchecksum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sha256\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mremote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchecksum\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mchecksum\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\conda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\conda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\conda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\conda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\conda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\conda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\conda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_data = fetch_lfw_people(min_faces_per_person=100, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788ba73-67b7-4577-b996-4a572a256899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd0e8e-bd4f-41f3-a31d-6504c1a9ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def process_lfw_data(\n",
    "    lfw_data, test_size: int=0.3, random_state: int=42\n",
    ") -> Tuple[np.array, np.array, np.array, np.array, Tuple[int, int, int, List[str]]]:\n",
    "    ### BEGIN YOUR SOLUTION ###\n",
    "    \n",
    "    ### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4952d62f-c837-434d-ba60-67db6cf2dabf",
   "metadata": {},
   "source": [
    "$\\quad$完成任务1后, 请**务必**运行下面的代码块做检查. 初次运行可能需要花费几分钟, 因为需要下载数据集. 不过, 运行完一次后再反复运行, 程序就将非常快地从内存中读取数据了.\n",
    "- 我们对`fetch_lfw_people`所筛选的人脸数据做出如下要求: 所提取的那些人必须至少录入了100张人脸图片, 且这些图片都将以0.4的比例被压缩."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c73434-1744-4e55-8ecf-f571a401c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_data = fetch_lfw_people(min_faces_per_person=100, resize=0.4)\n",
    "X_train, X_test, y_true_train, y_true_test, (H, W, n_classes, target_names) = process_lfw_data(lfw_data)\n",
    "H, W, n_classes, target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39fe020-7cf4-4fc7-9a91-8d1019581e17",
   "metadata": {},
   "source": [
    "# SVM模型超参数的探索\n",
    "\n",
    "$\\quad$我们下面先定性讨论超参数`C`与`gamma`对模型性能的影响, 再用网格搜索进行超参数优化. 为此, 请先运行下述代码块导入必要的库函数. 其中, [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn-model-selection-cross-val-score)函数用于交叉验证的平均得分的计算, 在不手动传入`scoring`参数的情况下, 对分类问题默认采用(验证集上的)accuracy作为评估指标."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570bfc7-728f-4d4a-8684-e1d9ed3851e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6618214-6594-40a7-bd94-fd32f9e2362b",
   "metadata": {},
   "source": [
    "## 超参数试验: 间隔软度与核函数系数\n",
    "\n",
    "- **任务2**: 分别讨论超参数对模型性能的影响.\n",
    "  - **任务2.1**: 其他条件不变, 取`C`分别为0.1、1、10;\n",
    "  - **任务2.2**: 其他条件不变, 取`gamma`分别为0.001、0.01、0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed1e46-66a8-4340-bf2b-1d9b814aa458",
   "metadata": {},
   "source": [
    "$\\quad$运行下述代码块, 观察结果, 在对应答题区解释你关于`C`值的发现.\n",
    "- 提示: `C`值起什么作用? 当它变化时, 欠拟合/过拟合的情况怎样?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7d973-7736-4db3-bf92-24ff458ac7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_vs_C = []\n",
    "for C in (0.1, 1, 10):\n",
    "    clf = SVC(C=C)\n",
    "    scores_vs_C.append(cross_val_score(clf, X_train, y_true_train, n_jobs=-1).mean())\n",
    "scores_vs_C\n",
    "\n",
    "### 任务2.1答题区(另起一行时请记得加注释符号#) ###\n",
    "### BEGIN YOUR SOLUTION ###\n",
    "#\n",
    "### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207e47e-9ecb-49aa-843b-a864fbda5347",
   "metadata": {},
   "source": [
    "$\\quad$运行下述代码块, 观察结果, 在对应答题区解释你关于`gamma`值的发现.\n",
    "- 提示: `gamma`值描述了(RBF)核函数的什么性质? 当它变化时, 欠拟合/过拟合的情况怎样?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8878b5d-bdcc-4614-918b-dc09fb8f7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_vs_gamma = []\n",
    "for gamma in (0.001, 0.01, 0.1):\n",
    "    clf = SVC(gamma=gamma)\n",
    "    scores_vs_gamma.append(cross_val_score(clf, X_train, y_true_train, n_jobs=-1).mean())\n",
    "scores_vs_gamma\n",
    "\n",
    "### 任务2.2答题区(另起一行时请记得加注释符号#) ###\n",
    "### BEGIN YOUR SOLUTION ###\n",
    "#\n",
    "### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04073369-95a3-4214-9320-2c2a354104a2",
   "metadata": {},
   "source": [
    "## 超参数的组合优化\n",
    "\n",
    "$\\quad$现在, 我们使用[`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)工具完成超参数优化.\n",
    "\n",
    "- **任务3**: 对超参数`C`与`gamma`进行基于5-折交叉验证的网格搜索(这是`GridSearchCV`的默认设置), 并对模型性能进行可视化.\n",
    "  - **任务3.1**: 完成函数`get_cv_data`的编写, 输入:\n",
    "    - 两个超参数各自的搜索空间`C_space`和`gamma_space`;\n",
    "    - 用于交叉验证的训练集`X_train`和`y_true_train`.\n",
    "  - 返回一个二元元组, 内容分别为:\n",
    "    - 用于三维作图的一个三元组, 分别为`C`、`gamma`和`score`(交叉验证平均得分)组成的二维数组(详见提示).\n",
    "    - 最优超参数配置, 以字典形式返回.\n",
    "  - **任务3.2**: 运行后续的两个代码块, 观察(三维)模型性能示意图, 分析`C`与`gamma`之间的关系."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086cf8e-522a-4fee-b787-86641fd8beaa",
   "metadata": {},
   "source": [
    "### 提示\n",
    "- 任务3.2中所做的图是以函数[`plot_surface`](https://matplotlib.org/stable/api/_as_gen/mpl_toolkits.mplot3d.axes3d.Axes3D.plot_surface.html#mpl_toolkits.mplot3d.axes3d.Axes3D.plot_surface)作出的三维空间内的曲面图, `x`轴、`y`轴分别为超参数`C`和`gamma`的取值, 而`z`轴则是交叉验证的平均性能. 这三根轴都必须是同样形状的二维数组, 行数等于`x`轴数据量、列数等于`y`轴数据量. 由于`GridSearchCV`函数对交叉验证结果的保存形式是(一维的)列表, 所以, 你也许需要: (1) 逐项遍历`cv_results_`中的超参数配置和对应得分, 先得到三个一维列表(三根轴上的数据); (2) 从这些一维列表出发, 构造三个对应的`np.array`数组, 并将它们按作图要求`reshape`为一个二维数组.\n",
    "- 机器配置为`c2_m4_cpu`, 是允许2核并行的. 所以, 建议设置`GridSearchCV`的参数`n_jobs`为2(或-1, 代表所有可用的核)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5b31b-2688-4410-8b56-0843b45504e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def get_cv_data(\n",
    "    C_space: np.array, gamma_space: np.array, X_train: np.array, y_true_train: np.array\n",
    ") -> Tuple[Tuple[np.array, np.array, np.array], Dict]:\n",
    "    ### BEGIN YOUR SOLUTION ###\n",
    "    \n",
    "    ### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed829b9-8f83-4289-a3e3-5a30a61ce4e8",
   "metadata": {},
   "source": [
    "$\\quad$完成该函数后, 请**务必**运行下面的代码块, 完成网格搜索. 如果你设置了`n_jobs=2`或`n_jobs=-1`, 该过程将预计需要5~6 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5e8dd-8dd7-4a7d-9e26-979c65316252",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_space = np.logspace(-0.5, 1.5, 8)\n",
    "gamma_space = np.logspace(-3, -1, 8)\n",
    "(X, Y, Z), best_params = get_cv_data(C_space, gamma_space, X_train, y_true_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e0a68d-35c4-4c05-866d-2014f03dac0e",
   "metadata": {},
   "source": [
    "$\\quad$完成网格搜索后, 你可以继续完成任务3.2: 运行下面的代码块, 解释你关于`C`与`gamma`值的发现.\n",
    "- 提示: 当增大/减小`gamma`值时, 为了达到更好的验证准确率, 我们需要相应地增大`C`值还是减小`C`值? 为什么?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687adc3-2f3d-4df8-9c8e-99abcb3f9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(np.log(X), np.log(Y), Z, cmap=\"coolwarm\")\n",
    "ax.set_xlabel(r\"$log{C}$\", weight='bold', size='x-large')\n",
    "ax.set_ylabel(r\"$log{\\gamma}$\", weight='bold', size='x-large')\n",
    "ax.set_title(\"Surface plot of validation accuracy\")\n",
    "plt.show()\n",
    "\n",
    "### 任务3.2答题区(另起一行时请记得加注释符号#) ###\n",
    "### BEGIN YOUR SOLUTION ###\n",
    "#\n",
    "### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1046e7e-3ced-4a77-b1d5-d6cc078fc92f",
   "metadata": {},
   "source": [
    "# SVM模型的训练、评估与解释\n",
    "\n",
    "$\\quad$最后, 我们以最优超参数配置`best_params`在全体训练集上进行模型的训练, 并对训练、测试性能作出评估."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a34cfe-5ce4-4d32-a552-cadfde3c4785",
   "metadata": {},
   "source": [
    "## 训练与评估\n",
    "\n",
    "- **任务4**: 完成函数`train_and_eval`的编写, 输入:\n",
    "  - `best_params`, 经过超参数优化后的最优配置;\n",
    "  - `X_train`、`X_test`、`y_true_train`、`y_true_test`, 为训练集和测试集的对应数据.\n",
    "- 返回: 三元元组, 内容分别为:\n",
    "  - 训练好的模型对象`clf`;\n",
    "  - 训练集上的**混淆矩阵**(confusion matrix)`cm_train`;\n",
    "  - 测试集上的混淆矩阵`cm_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320d317-8da3-4f5f-9499-0f372e975493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def train_and_eval(\n",
    "    best_params, X_train: np.array, X_test: np.array, y_true_train: np.array, y_true_test: np.array\n",
    ") -> Tuple[object, np.array, np.array]:\n",
    "    ### BEGIN YOUR SOLUTION ###\n",
    "    \n",
    "    ### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23914d8c-83ee-4f02-9abe-0b5ccb7b30f8",
   "metadata": {},
   "source": [
    "$\\quad$完成该函数后, 请**务必**运行下面的代码块, 完成训练与评估的过程."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c820a8-9592-4f2f-8dec-8342c4807433",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, cm_train, cm_test = train_and_eval(\n",
    "    best_params, X_train, X_test, y_true_train, y_true_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898c2ff-1863-44d1-a7ca-0feca69f6ee8",
   "metadata": {},
   "source": [
    "$\\quad$完成训练/评估后, 请运行下面的两个代码块, 分别对训练集、测试集上的混淆矩阵进行可视化."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76209626-db5a-481d-8a21-9f6d35a8c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "cm_train = pd.DataFrame(cm_train, index=target_names, columns=target_names)\n",
    "sns.heatmap(cm_train, annot=True, fmt=\".0f\")\n",
    "plt.title(\"Confusion matrix on training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2f0b5-e08c-4af2-bc0a-06d6e2ceff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = pd.DataFrame(cm_test, index=target_names, columns=target_names)\n",
    "sns.heatmap(cm_test, annot=True, fmt=\".0f\")\n",
    "plt.title(\"Confusion matrix on test set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc279c-afb1-4411-aa8f-eb1b255dff82",
   "metadata": {},
   "source": [
    "## 支持向量(support vector)的可视化\n",
    "\n",
    "$\\quad$现在, 我们简单查看各个类别的支持向量. 它们是模型决策的依据.\n",
    "\n",
    "- **任务5**: 完成函数`plot_support_vectors`的编写, 实现如下功能: 对每个类别, 在该类别的所有支持向量中随机抽取一个, 以[`plt.imshow`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib-pyplot-imshow)函数分别将其(照片)绘制出来. 输入:\n",
    "  - `clf`, 训练好的分类模型;\n",
    "  - `target_names`, 人名构成的列表;\n",
    "  - 图片尺寸`height`、`width`;\n",
    "  - 随机数种子`seed`, 用于保持随机算法的可复现性.\n",
    "\n",
    "不返回任何内容. 一些作图要求:\n",
    "- 所有人脸照片排在同一行;\n",
    "- 图片标题为两行文字, 第一行: `True: <true_name>`, 第二行: `Pred: <pred_name>`. 其中, `true_name`为该样本的真实标签对应的人名, `pred_name`为该样本的预测标签对应的人名.\n",
    "\n",
    "其余格式自选, 不作硬性要求."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afe28a-7b94-4b96-8b35-4441dd1333f0",
   "metadata": {},
   "source": [
    "### 提示\n",
    "- 可以采用[`random.choice`](https://docs.python.org/3/library/random.html#random.choice)函数进行随机采样. 设置随机数种子的方法为[`random.seed`](https://docs.python.org/3/library/random.html#random.seed).\n",
    "- 支持向量储存在模型对象的`support_vectors_`属性中, 已经按类别标签值由小到大排序; 每个类别的支持向量的总数储存在模型对象`n_support_`属性中, 也同样按类别标签值由小到大排序.\n",
    "- 切记每个支持向量是“压扁”的图片, 需要按照尺寸参数进行`reshape`, 再绘制."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15f261-365f-48a6-8860-4c5ea52c41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_support_vectors(clf, target_names: List[str], height: int, width: int, seed: int=42):\n",
    "    ### BEGIN YOUR SOLUTION ###\n",
    "    \n",
    "    ### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a81377-8805-49aa-b16c-f8a5b702acd5",
   "metadata": {},
   "source": [
    "$\\quad$完成该函数后, 就可以运行下面的代码块查看支持向量啦🥳! 怎么样? 你的模型是不是非常不脸盲了呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b361e-8584-4876-b401-861721db018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_support_vectors(clf, target_names, H, W, n_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
