{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d05e36-6b0a-4802-8550-450e46c4e734",
   "metadata": {},
   "source": [
    "# 背景概述\n",
    "\n",
    "$\\quad$你是脸盲吗😱? 不管是不是, 都欢迎完成本次上机作业! 我们将构建一个基于支持向量机的人脸识别器, 判定某张人脸图片归属于数据库内的哪个人. 我们将使用[LFW(Labeled Faces in the Wild)数据集](https://vis-www.cs.umass.edu/lfw/), 其中含有若干张人脸图片(RGB三通道彩图)及其对应的人名."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a9e16-039d-4946-b4dd-75f6e37c0aad",
   "metadata": {},
   "source": [
    "# 数据的读取与清洗\n",
    "\n",
    "$\\quad$我们可以利用[`sklearn.datasets`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets)模块的函数[`fetch_lfw_people`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html#sklearn.datasets.fetch_lfw_people)自动在特定的条件要求下进行人脸图片抓取.\n",
    "\n",
    "- **任务1**: 完成函数`process_lfw_data`的编写, 实现数据集的预处理、训练-测试分拆与描述性参数的整理. 输入:\n",
    "  - `lfw_data`, 经过`fetch_lfw_people`函数下载(或加载好)的数据集. 这是一个类似于字典的数据结构, 类属性保存了关于这个数据集的若干描述性信息, 例如`images`、`target`、`target_names`等.\n",
    "  - `test_size`, 测试集大小. 默认值为0.3, 即训练集 : 测试集 = 7 : 3. 进行拆分时, 要求对原数据集做一次随机打乱(`shuffle=True`).\n",
    "  - `random_state`, 用于传入`sklearn`中涉及随机性的函数(例如[`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn-model-selection-train-test-split)), 保证可复现性. 默认值为42.\n",
    "- 返回一个五元元组, 前四个元素分别是拆分好的`X_train`、`X_test`、`y_true_train`、`y_true_test`, 最后一个元素是一个元组, 内容按顺序包括:\n",
    "  - 人脸图片高度`H`;\n",
    "  - 人脸图片宽度`W`;\n",
    "  - 数据集中涵盖了多少人`n_classes`;\n",
    "  - 数据集中涵盖的那些人的名字`target_names`, 要求返回的是一个列表.\n",
    "- 由于`X`的取值区间是`[0, 255)`, 因此要求对`X`进行数据重标度: 各个值除以255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ca3e7-328c-4136-aa8d-79cd7fcd0ae4",
   "metadata": {},
   "source": [
    "### 提示\n",
    "- `fetch_lfw_people`函数默认将RGB三个色彩通道加工处理成单通道的灰度图, 因此不需要担心多个色彩通道的问题.\n",
    "- 由于数据集被施加了若干限制条件(详见下一个代码块), 因此你在编写函数时, 需要访问`lfw_data`对应的类属性, 而不能直接根据官方文档的数字直接抄写."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c9228d-7cb5-4982-b91e-deed3856e19a",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_lfw_people\n\u001b[1;32m----> 2\u001b[0m lfw_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_lfw_people\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_faces_per_person\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\site-packages\\sklearn\\datasets\\_lfw.py:328\u001b[0m, in \u001b[0;36mfetch_lfw_people\u001b[1;34m(data_home, funneled, resize, min_faces_per_person, color, slice_, download_if_missing, return_X_y)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_lfw_people\u001b[39m(\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    236\u001b[0m     data_home\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m     return_X_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    244\u001b[0m ):\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;124;03m\"\"\"Load the Labeled Faces in the Wild (LFW) people dataset \\\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m(classification).\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 0.20\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m     lfw_home, data_folder_path \u001b[38;5;241m=\u001b[39m \u001b[43m_check_fetch_lfw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunneled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunneled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_if_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_if_missing\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading LFW people faces from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, lfw_home)\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;66;03m# wrap the loader in a memoizing function that will return memmaped data\u001b[39;00m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;66;03m# arrays for optimal memory usage\u001b[39;00m\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\site-packages\\sklearn\\datasets\\_lfw.py:88\u001b[0m, in \u001b[0;36m_check_fetch_lfw\u001b[1;34m(data_home, funneled, download_if_missing)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download_if_missing:\n\u001b[0;32m     87\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading LFW metadata: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, target\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m---> 88\u001b[0m     \u001b[43m_fetch_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlfw_home\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is missing\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m target_filepath)\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\site-packages\\sklearn\\datasets\\_base.py:1324\u001b[0m, in \u001b[0;36m_fetch_remote\u001b[1;34m(remote, dirname)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;124;03m\"\"\"Helper function to download a remote dataset into path\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m \n\u001b[0;32m   1304\u001b[0m \u001b[38;5;124;03mFetch a dataset pointed by remote's url, save into path using remote's\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;124;03m    Full path of the created file.\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m file_path \u001b[38;5;241m=\u001b[39m remote\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;28;01mif\u001b[39;00m dirname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m join(dirname, remote\u001b[38;5;241m.\u001b[39mfilename)\n\u001b[1;32m-> 1324\u001b[0m \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m checksum \u001b[38;5;241m=\u001b[39m _sha256(file_path)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remote\u001b[38;5;241m.\u001b[39mchecksum \u001b[38;5;241m!=\u001b[39m checksum:\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\urllib\\request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    242\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\language\\anaconda\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_data = fetch_lfw_people(min_faces_per_person=100, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd0e8e-bd4f-41f3-a31d-6504c1a9ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def process_lfw_data(\n",
    "    lfw_data, test_size: int=0.3, random_state: int=42\n",
    ") -> Tuple[np.array, np.array, np.array, np.array, Tuple[int, int, int, List[str]]]:\n",
    "    ### BEGIN YOUR SOLUTION ###\n",
    "    \n",
    "    ### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4952d62f-c837-434d-ba60-67db6cf2dabf",
   "metadata": {},
   "source": [
    "$\\quad$完成任务1后, 请**务必**运行下面的代码块做检查. 初次运行可能需要花费几分钟, 因为需要下载数据集. 不过, 运行完一次后再反复运行, 程序就将非常快地从内存中读取数据了.\n",
    "- 我们对`fetch_lfw_people`所筛选的人脸数据做出如下要求: 所提取的那些人必须至少录入了100张人脸图片, 且这些图片都将以0.4的比例被压缩."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c73434-1744-4e55-8ecf-f571a401c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_data = fetch_lfw_people(min_faces_per_person=100, resize=0.4)\n",
    "X_train, X_test, y_true_train, y_true_test, (H, W, n_classes, target_names) = process_lfw_data(lfw_data)\n",
    "H, W, n_classes, target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39fe020-7cf4-4fc7-9a91-8d1019581e17",
   "metadata": {},
   "source": [
    "# SVM模型超参数的探索\n",
    "\n",
    "$\\quad$我们下面先定性讨论超参数`C`与`gamma`对模型性能的影响, 再用网格搜索进行超参数优化. 为此, 请先运行下述代码块导入必要的库函数. 其中, [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn-model-selection-cross-val-score)函数用于交叉验证的平均得分的计算, 在不手动传入`scoring`参数的情况下, 对分类问题默认采用(验证集上的)accuracy作为评估指标."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570bfc7-728f-4d4a-8684-e1d9ed3851e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6618214-6594-40a7-bd94-fd32f9e2362b",
   "metadata": {},
   "source": [
    "## 超参数试验: 间隔软度与核函数系数\n",
    "\n",
    "- **任务2**: 分别讨论超参数对模型性能的影响.\n",
    "  - **任务2.1**: 其他条件不变, 取`C`分别为0.1、1、10;\n",
    "  - **任务2.2**: 其他条件不变, 取`gamma`分别为0.001、0.01、0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed1e46-66a8-4340-bf2b-1d9b814aa458",
   "metadata": {},
   "source": [
    "$\\quad$运行下述代码块, 观察结果, 在对应答题区解释你关于`C`值的发现.\n",
    "- 提示: `C`值起什么作用? 当它变化时, 欠拟合/过拟合的情况怎样?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7d973-7736-4db3-bf92-24ff458ac7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_vs_C = []\n",
    "for C in (0.1, 1, 10):\n",
    "    clf = SVC(C=C)\n",
    "    scores_vs_C.append(cross_val_score(clf, X_train, y_true_train, n_jobs=-1).mean())\n",
    "scores_vs_C\n",
    "\n",
    "### 任务2.1答题区(另起一行时请记得加注释符号#) ###\n",
    "### BEGIN YOUR SOLUTION ###\n",
    "#\n",
    "### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207e47e-9ecb-49aa-843b-a864fbda5347",
   "metadata": {},
   "source": [
    "$\\quad$运行下述代码块, 观察结果, 在对应答题区解释你关于`gamma`值的发现.\n",
    "- 提示: `gamma`值描述了(RBF)核函数的什么性质? 当它变化时, 欠拟合/过拟合的情况怎样?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8878b5d-bdcc-4614-918b-dc09fb8f7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_vs_gamma = []\n",
    "for gamma in (0.001, 0.01, 0.1):\n",
    "    clf = SVC(gamma=gamma)\n",
    "    scores_vs_gamma.append(cross_val_score(clf, X_train, y_true_train, n_jobs=-1).mean())\n",
    "scores_vs_gamma\n",
    "\n",
    "### 任务2.2答题区(另起一行时请记得加注释符号#) ###\n",
    "### BEGIN YOUR SOLUTION ###\n",
    "#\n",
    "### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04073369-95a3-4214-9320-2c2a354104a2",
   "metadata": {},
   "source": [
    "## 超参数的组合优化\n",
    "\n",
    "$\\quad$现在, 我们使用[`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)工具完成超参数优化.\n",
    "\n",
    "- **任务3**: 对超参数`C`与`gamma`进行基于5-折交叉验证的网格搜索(这是`GridSearchCV`的默认设置), 并对模型性能进行可视化.\n",
    "  - **任务3.1**: 完成函数`get_cv_data`的编写, 输入:\n",
    "    - 两个超参数各自的搜索空间`C_space`和`gamma_space`;\n",
    "    - 用于交叉验证的训练集`X_train`和`y_true_train`.\n",
    "  - 返回一个二元元组, 内容分别为:\n",
    "    - 用于三维作图的一个三元组, 分别为`C`、`gamma`和`score`(交叉验证平均得分)组成的二维数组(详见提示).\n",
    "    - 最优超参数配置, 以字典形式返回.\n",
    "  - **任务3.2**: 运行后续的两个代码块, 观察(三维)模型性能示意图, 分析`C`与`gamma`之间的关系."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086cf8e-522a-4fee-b787-86641fd8beaa",
   "metadata": {},
   "source": [
    "### 提示\n",
    "- 任务3.2中所做的图是以函数[`plot_surface`](https://matplotlib.org/stable/api/_as_gen/mpl_toolkits.mplot3d.axes3d.Axes3D.plot_surface.html#mpl_toolkits.mplot3d.axes3d.Axes3D.plot_surface)作出的三维空间内的曲面图, `x`轴、`y`轴分别为超参数`C`和`gamma`的取值, 而`z`轴则是交叉验证的平均性能. 这三根轴都必须是同样形状的二维数组, 行数等于`x`轴数据量、列数等于`y`轴数据量. 由于`GridSearchCV`函数对交叉验证结果的保存形式是(一维的)列表, 所以, 你也许需要: (1) 逐项遍历`cv_results_`中的超参数配置和对应得分, 先得到三个一维列表(三根轴上的数据); (2) 从这些一维列表出发, 构造三个对应的`np.array`数组, 并将它们按作图要求`reshape`为一个二维数组.\n",
    "- 机器配置为`c2_m4_cpu`, 是允许2核并行的. 所以, 建议设置`GridSearchCV`的参数`n_jobs`为2(或-1, 代表所有可用的核)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5b31b-2688-4410-8b56-0843b45504e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def get_cv_data(\n",
    "    C_space: np.array, gamma_space: np.array, X_train: np.array, y_true_train: np.array\n",
    ") -> Tuple[Tuple[np.array, np.array, np.array], Dict]:\n",
    "    ### BEGIN YOUR SOLUTION ###\n",
    "    \n",
    "    ### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed829b9-8f83-4289-a3e3-5a30a61ce4e8",
   "metadata": {},
   "source": [
    "$\\quad$完成该函数后, 请**务必**运行下面的代码块, 完成网格搜索. 如果你设置了`n_jobs=2`或`n_jobs=-1`, 该过程将预计需要5~6 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5e8dd-8dd7-4a7d-9e26-979c65316252",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_space = np.logspace(-0.5, 1.5, 8)\n",
    "gamma_space = np.logspace(-3, -1, 8)\n",
    "(X, Y, Z), best_params = get_cv_data(C_space, gamma_space, X_train, y_true_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e0a68d-35c4-4c05-866d-2014f03dac0e",
   "metadata": {},
   "source": [
    "$\\quad$完成网格搜索后, 你可以继续完成任务3.2: 运行下面的代码块, 解释你关于`C`与`gamma`值的发现.\n",
    "- 提示: 当增大/减小`gamma`值时, 为了达到更好的验证准确率, 我们需要相应地增大`C`值还是减小`C`值? 为什么?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687adc3-2f3d-4df8-9c8e-99abcb3f9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(np.log(X), np.log(Y), Z, cmap=\"coolwarm\")\n",
    "ax.set_xlabel(r\"$log{C}$\", weight='bold', size='x-large')\n",
    "ax.set_ylabel(r\"$log{\\gamma}$\", weight='bold', size='x-large')\n",
    "ax.set_title(\"Surface plot of validation accuracy\")\n",
    "plt.show()\n",
    "\n",
    "### 任务3.2答题区(另起一行时请记得加注释符号#) ###\n",
    "### BEGIN YOUR SOLUTION ###\n",
    "#\n",
    "### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1046e7e-3ced-4a77-b1d5-d6cc078fc92f",
   "metadata": {},
   "source": [
    "# SVM模型的训练、评估与解释\n",
    "\n",
    "$\\quad$最后, 我们以最优超参数配置`best_params`在全体训练集上进行模型的训练, 并对训练、测试性能作出评估."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a34cfe-5ce4-4d32-a552-cadfde3c4785",
   "metadata": {},
   "source": [
    "## 训练与评估\n",
    "\n",
    "- **任务4**: 完成函数`train_and_eval`的编写, 输入:\n",
    "  - `best_params`, 经过超参数优化后的最优配置;\n",
    "  - `X_train`、`X_test`、`y_true_train`、`y_true_test`, 为训练集和测试集的对应数据.\n",
    "- 返回: 三元元组, 内容分别为:\n",
    "  - 训练好的模型对象`clf`;\n",
    "  - 训练集上的**混淆矩阵**(confusion matrix)`cm_train`;\n",
    "  - 测试集上的混淆矩阵`cm_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320d317-8da3-4f5f-9499-0f372e975493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def train_and_eval(\n",
    "    best_params, X_train: np.array, X_test: np.array, y_true_train: np.array, y_true_test: np.array\n",
    ") -> Tuple[object, np.array, np.array]:\n",
    "    ### BEGIN YOUR SOLUTION ###\n",
    "    \n",
    "    ### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23914d8c-83ee-4f02-9abe-0b5ccb7b30f8",
   "metadata": {},
   "source": [
    "$\\quad$完成该函数后, 请**务必**运行下面的代码块, 完成训练与评估的过程."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c820a8-9592-4f2f-8dec-8342c4807433",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, cm_train, cm_test = train_and_eval(\n",
    "    best_params, X_train, X_test, y_true_train, y_true_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898c2ff-1863-44d1-a7ca-0feca69f6ee8",
   "metadata": {},
   "source": [
    "$\\quad$完成训练/评估后, 请运行下面的两个代码块, 分别对训练集、测试集上的混淆矩阵进行可视化."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76209626-db5a-481d-8a21-9f6d35a8c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "cm_train = pd.DataFrame(cm_train, index=target_names, columns=target_names)\n",
    "sns.heatmap(cm_train, annot=True, fmt=\".0f\")\n",
    "plt.title(\"Confusion matrix on training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2f0b5-e08c-4af2-bc0a-06d6e2ceff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = pd.DataFrame(cm_test, index=target_names, columns=target_names)\n",
    "sns.heatmap(cm_test, annot=True, fmt=\".0f\")\n",
    "plt.title(\"Confusion matrix on test set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc279c-afb1-4411-aa8f-eb1b255dff82",
   "metadata": {},
   "source": [
    "## 支持向量(support vector)的可视化\n",
    "\n",
    "$\\quad$现在, 我们简单查看各个类别的支持向量. 它们是模型决策的依据.\n",
    "\n",
    "- **任务5**: 完成函数`plot_support_vectors`的编写, 实现如下功能: 对每个类别, 在该类别的所有支持向量中随机抽取一个, 以[`plt.imshow`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib-pyplot-imshow)函数分别将其(照片)绘制出来. 输入:\n",
    "  - `clf`, 训练好的分类模型;\n",
    "  - `target_names`, 人名构成的列表;\n",
    "  - 图片尺寸`height`、`width`;\n",
    "  - 随机数种子`seed`, 用于保持随机算法的可复现性.\n",
    "\n",
    "不返回任何内容. 一些作图要求:\n",
    "- 所有人脸照片排在同一行;\n",
    "- 图片标题为两行文字, 第一行: `True: <true_name>`, 第二行: `Pred: <pred_name>`. 其中, `true_name`为该样本的真实标签对应的人名, `pred_name`为该样本的预测标签对应的人名.\n",
    "\n",
    "其余格式自选, 不作硬性要求."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afe28a-7b94-4b96-8b35-4441dd1333f0",
   "metadata": {},
   "source": [
    "### 提示\n",
    "- 可以采用[`random.choice`](https://docs.python.org/3/library/random.html#random.choice)函数进行随机采样. 设置随机数种子的方法为[`random.seed`](https://docs.python.org/3/library/random.html#random.seed).\n",
    "- 支持向量储存在模型对象的`support_vectors_`属性中, 已经按类别标签值由小到大排序; 每个类别的支持向量的总数储存在模型对象`n_support_`属性中, 也同样按类别标签值由小到大排序.\n",
    "- 切记每个支持向量是“压扁”的图片, 需要按照尺寸参数进行`reshape`, 再绘制."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15f261-365f-48a6-8860-4c5ea52c41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_support_vectors(clf, target_names: List[str], height: int, width: int, seed: int=42):\n",
    "    ### BEGIN YOUR SOLUTION ###\n",
    "    \n",
    "    ### END YOUR SOLUTION ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a81377-8805-49aa-b16c-f8a5b702acd5",
   "metadata": {},
   "source": [
    "$\\quad$完成该函数后, 就可以运行下面的代码块查看支持向量啦🥳! 怎么样? 你的模型是不是非常不脸盲了呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b361e-8584-4876-b401-861721db018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_support_vectors(clf, target_names, H, W, n_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
