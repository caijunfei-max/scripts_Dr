{"cells":[{"cell_type":"markdown","source":"# 背景概述\n\n$\\quad$你喜欢吃披萨吗😍? 不管你喜欢与否, 都欢迎完成本次上机作业! 我们将构建一个基于卷积网络的二元分类器, 用于识别给定的一张图片是否是披萨的照片.\n\n$\\quad$请先运行下述两个代码块, 完成`ray`库的安装.","metadata":{},"id":"2cd7dd5b-0082-42a4-960c-a75240726d22"},{"cell_type":"code","source":"!pip install -U ipywidgets\n!pip install -U \"ray[data,train,tune,serve]\"","metadata":{},"execution_count":null,"id":"7408c7af-39a5-482c-b396-1376a760eeb0"},{"cell_type":"code","source":"import ray","metadata":{},"execution_count":null,"id":"67c5ffb8-8590-47dd-abcd-4dbaea409683"},{"cell_type":"markdown","source":"$\\quad$如果希望前期模型训练和数据集拆分的结果具有**可复现性**(reproducibility), 请运行下述的代码块, 给随机算法设置好随机数种子.","metadata":{},"id":"e8deff5d-0b27-4791-af73-2997503867ba"},{"cell_type":"code","source":"import torch\n\ndef set_seeds(seed: int=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n\nset_seeds()","metadata":{},"execution_count":null,"id":"512aa1a9-cf4a-469c-bd0c-e9d40c4dfdd8"},{"cell_type":"markdown","source":"# 数据清洗与可视化\n\n$\\quad$我们将使用的数据集为`pizza_or_not`, 包含两个子目录. 子目录`pizza`存有983张披萨(阳性)的照片, 子目录`not_pizza`存有983张其他种类食物(阴性)的照片. 每张照片尺寸不一, 但均为彩照, 即含有三个色彩通道(采用[YUV色彩空间](https://dexonsystems.com/blog/rgb-yuv-color-spaces)). 由于文件的结构与信息组织方式相对复杂, 我们定义一个继承自[`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)类的子类, 用于定义从指定文件中读取输入`X`和标签`y_true`的方式.\n\n$\\quad$**任务1**: 完成数据集子类`PizzaOrNotDataset`的编写, 你需要依据已有的方法和属性, 实现如下两个方法:\n- `__len__(self)`方法, 返回数据集的总长度(总样本数). 这是一个magic method, 在调用函数`len(...)`时使用.\n- `__getitem__(self, idx)`方法, 根据给定索引值`idx`返回二元元组`(X, y_true)`, 前者为输入, 后者为标签, **都需要设置为`torch.tensor`格式**. 这是一个magic method, 在调用索引号`[...]`时使用. 只需要实现**索引**(indexing)即可, 无需支持**切片**(slicing)功能.\n  - 要求: 索引值处于区间`[0, 983)`内时返回阳性样本的对应文件, 处于区间`[983, 1966)`时返回阴性样本的对应文件, 序号以Python内置库函数[`os.listdir()`](https://docs.python.org/3/library/os.html#os.listdir)排出的顺序给定.\n\n初始化方法中涉及的参数解释如下:\n- `root_dir`为根目录, 在本例中即为`pizza_or_not`数据集的存储路径.\n- `transform`定义了图像数据的变换. 如果该参数为空(`None`), 则`__getitem__()`方法将给出的输入`X`是一个[`PIL.Image.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image)对象; 如果不为空, 则`X`就是存储于设备`self.device`上的一个`tensor`对象.\n\n### 提示\n- 类属性的访问需要加前缀`self.`, 例如`self.device`、`self.transform`等.\n- 图片文件的读入可用[`PIL.Image.open()`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.open)函数完成. 读入后, 你所得到的`PIL.Image.Image`对象可由[`torchvision.transforms.ToTensor()`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor)方法转换成`torch.tensor`格式.\n- 本次作业建议大家在免费的`c2_m4_cpu`机器上调试完代码后, 利用GPU资源完成正式的超参数优化与模型训练(重新连接机器后, 点击restart kernel and run all cells按钮). 作业内测时使用的GPU设备是`c12_m46_1 * NVIDIA GPU B`, 效率约有4倍的提升(~20s / epoch, 预计从头运行notebook的总花费约45min、5.25元).\n  - 数据集的初始化方法含有参数`device`, 所以, 在`__getitem__()`方法中, 你需要保证你返回的`tensor`对象被搬运到了正确的`self.device`属性上. 可以利用[`tensor.to()`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch-tensor-to)方法.\n  - 模型在每次完成创建后也应当搬运到`device`上, 稍后详述.\n  - 课程预算有限, 请确保你的代码不需要大修后再连接GPU资源, 并谨慎使用.\n- 如果想在`device`上原位构造新的`tensor`对象, 请使用小写的t, 即`torch.tensor(..., device=self.device)`而非`torch.Tensor(..., device=self.device)`, 后者[不支持GPU上直接创建](https://discuss.pytorch.org/t/cannot-construct-tensor-directly-on-gpu-in-torch-1-10-1/153751).","metadata":{},"id":"54a8fbd6-e0f5-405e-b841-f6953d56db4a"},{"cell_type":"code","source":"import os\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\nclass PizzaOrNotDataset(Dataset):\n    def __init__(self, root_dir: str, transform=None, device=\"cpu\"):\n        self.positive_idxs = os.listdir(os.path.join(root_dir, \"pizza\"))\n        self.negative_idxs = os.listdir(os.path.join(root_dir, \"not_pizza\"))\n        self.root_dir = root_dir\n        self.transform = transform\n        self.device = device\n    def __len__(self):\n        ### BEGIN YOUR SOLUTION ###\n        raise NotImplementedError()\n        ### END YOUR SOLUTION ###\n    def __getitem__(self, idx: int):\n        ### BEGIN YOUR SOLUTION ###\n        raise NotImplementedError()\n        ### END YOUR SOLUTION ###\n    @property\n    def n_positive(self):\n        return len(self.positive_idxs)\n    @property\n    def n_negative(self):\n        return len(self.negative_idxs)","metadata":{},"execution_count":null,"id":"7c7ee4ca-d8a0-4e08-979f-58ac722db8d9"},{"cell_type":"markdown","source":"$\\quad$完成任务1后, 请**务必**运行下面的代码块进行检查. 我们定义的图像变换操作流是: (1) 格式转换为tensor(同时, PyTorch会自动将每个像素值作重标度, 除以255); (2) 图片的大小调整为128x128, 即总共16384个像素.","metadata":{},"id":"13d076c9-c40d-491a-9a01-bcd8b9380abc"},{"cell_type":"code","source":"from torchvision.transforms import Compose, ToTensor, Resize\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\npizza_or_not_dataset = PizzaOrNotDataset(\n    root_dir=\"/bohr/MLInChem-468s/v1/\",\n    transform=Compose([ToTensor(), Resize((128, 128))]),\n    device=device\n)\nX_demo, y_true_demo = pizza_or_not_dataset[0]\nX_demo.shape, y_true_demo","metadata":{},"execution_count":null,"id":"16123759-3453-427b-b0be-ea52f24e67e5"},{"cell_type":"markdown","source":"$\\quad$检查完成后, 你可以运行下面的代码块, 完成其中部分样本的可视化. Hmmm! 怎么样, 有没有心动的一款😋!","metadata":{},"id":"98dc77ff-32b0-45b7-baa8-bf934a1b7aec"},{"cell_type":"code","source":"from typing import List\nfrom matplotlib import pyplot as plt\n\ndef visualize_data(samples: List, n_rows: int):\n    plt.figure(figsize=(10, 3))\n    n_samples = len(samples)\n    for i, sample in enumerate(samples):\n        img, label = sample\n        plt.subplot(n_rows, n_samples // n_rows, i + 1)\n        plt.imshow(img.permute((1, 2, 0)).cpu(), interpolation=\"none\")\n        plt.title(f\"label: {int(label.item())}\")\n        plt.axis(\"off\")\n    plt.show()\n\nvisualize_data(samples=[pizza_or_not_dataset[i] for i in (300, 600, 900, 1200, 1500, 1800)], n_rows=2)","metadata":{},"execution_count":null,"id":"1e9e89e9-8183-4f72-8e30-bad0bef8feaf"},{"cell_type":"markdown","source":"# 模型的搭建\n\n$\\quad$我们搭建的模型架构如下图所示. 这是一个卷积网络+全连接网络的架构, 其中, 卷积模块`ConvModule`包含两组卷积-最大池化操作, 并且第二次的卷积核有所扩张, 以提取更广域的像素信息. 模型的最终输出由Sigmoid函数激活, 并解释为(二分类问题中的)阳性概率. 图中默认采用3x3卷积核和1024大小的隐藏层, 这两个值将在稍后作为模型超参数进行调整.\n\n![alt image.png](https://bohrium.oss-cn-zhangjiakou.aliyuncs.com/article/17993/e3280ab6cfff400c81b1498c88c11640/AaSUBYAtPBRcwapsIaMEDQ.png)\n\n$\\quad$以下是卷积模块`ConvModule`的代码实现.","metadata":{},"id":"09d6b9fd-1346-4aaf-be12-a5e9971fe547"},{"cell_type":"code","source":"from torch import nn\nfrom torch.nn import functional as F\n\nclass ConvModule(nn.Module):\n    def __init__(self, kernel_size=3):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 8, kernel_size=kernel_size, dilation=1, padding=\"same\")\n        self.pooling1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(8, 16, kernel_size=kernel_size, dilation=3, padding=\"same\")\n        self.pooling2 = nn.MaxPool2d(kernel_size=2, stride=2)\n    def forward(self, X):\n        X = self.pooling1(F.relu(self.conv1(X)))\n        X = self.pooling2(F.relu(self.conv2(X)))\n        return X","metadata":{},"execution_count":null,"id":"c99e1123-c4d0-4edf-8b45-003abfb1830a"},{"cell_type":"markdown","source":"$\\quad$**任务2**: 根据已给出的`ConvModule`模块代码以及图示模型架构, 完成模型子类`PizzaOrNotModel`的编写. 你需要实现如下两个方法:\n- `__init__(self, kernel_size, num_hiddens)`方法, 根据给定的卷积核大小和隐藏层大小, 以类属性的形式定义必要的组件和层;\n- `forward(self, X)`方法, 给出前向传播的输出.\n\n### 提示\n- PyTorch建议使用[`torch.sigmoid`](https://pytorch.org/docs/stable/generated/torch.sigmoid.html#torch-sigmoid)接口, 而非[`F.sigmoid`](https://pytorch.org/docs/stable/generated/torch.nn.functional.sigmoid.html#torch-nn-functional-sigmoid).\n- 卷积模块`ConvModule`的输出形状为`(B, C, H, W)`, 分别代表: 批次大小、通道数(上述模型中为16)、高度(上述数据经过`ConvModule`变换后为32)、宽度(上述数据经过`ConvModule`变换后为32). 你需要将后三个维度“压扁”为一维再送入全连接层. 可参考[`tensor.reshape`](https://pytorch.org/docs/stable/generated/torch.Tensor.reshape.html#torch-tensor-reshape)方法.","metadata":{},"id":"2a8d83cc-67b9-4f35-92a4-252dcfddf057"},{"cell_type":"code","source":"class PizzaOrNotModel(nn.Module):\n    def __init__(self, kernel_size=3, num_hiddens=1024):\n        super().__init__()\n        ### BEGIN YOUR SOLUTION ###\n        raise NotImplementedError()\n        ### END YOUR SOLUTION ###\n    def forward(self, X):\n        ### BEGIN YOUR SOLUTION ###\n        raise NotImplementedError()\n        ### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"id":"76fac3c6-19eb-4058-8e67-32a24083de34"},{"cell_type":"markdown","source":"$\\quad$完成任务2后, 请**务必**运行下面的代码块进行检查. 注意到`model.to(device)`的作用即是将模型搬运到对应的设备上.","metadata":{},"id":"4dcb0fa2-bc5e-4bfd-a96a-91710a0acfcd"},{"cell_type":"code","source":"pizza_or_not_model = PizzaOrNotModel().to(device)\npizza_or_not_model(X_demo.unsqueeze(0))","metadata":{},"execution_count":null,"id":"29218ae2-8a21-4764-87c2-3a77f37e8409"},{"cell_type":"markdown","source":"# 超参数对模型训练的影响: 试验与优化\n\n$\\quad$我们下面先定性讨论模型超参数对训练过程的影响, 再利用`ray`进行超参数的网格搜索优化.","metadata":{},"id":"6efc0402-d8dd-470b-91f2-7ae2171d67cd"},{"cell_type":"markdown","source":"## 搭建训练组件\n\n$\\quad$**任务3**: 根据以下两个给出的函数`train_model_epoch()`和`evaluate_model()`, 完成函数`train_model`的编写. 输入:\n- 训练集`train_subset`与验证集`val_subset`.\n- 训练配置字典`config`, 包含关键字`batch_size`、`kernel_size`、`num_hiddens`、`lr`.\n- 训练周期数`num_epochs`, 默认值为5.\n- 描述设备的字符串`device`, 默认为`cpu`, 如果选择了GPU机器, 则参数值为`cuda`.\n- 逻辑变量`log`, 表示是否在训练过程中输出训练记录. 如果为`True`, 要求报告: 训练周期数、特定批次的平均损失函数(详见`train_model_epoch()`函数)、该周期的平均损失函数, 报告信息的格式可以自选.\n- 逻辑变量`save`, 表示是否在完成训练后保存模型. 如果为`True`, 要求在notebook同目录下储存训练完成后的模型参数至`PizzaOrNotModel.pt`.\n\n返回四元元组: 每个周期上的 (1) 训练集损失函数; (2) 训练集准确率(accuracy); (3) 验证集损失函数; (4) 验证集准确率. 其中, 要求优化器选择[`torch.optim.SGD`](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#sgd)(取参数`momentum`为0.5), 损失函数选择[`nn.BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#bceloss)且对批次求平均.\n\n### 提示\n- 函数`train_model_epoch()`用于单个周期的训练, 输入模型、训练用`DataLoader`对象、优化器`optimizer`、损失函数`criterion`和记录标记`log`, 进行单周期的模型参数优化, 返回该周期在训练集上的平均损失函数.\n- 函数`evaluate_model()`用于模型评估, 输入模型、评估用`DataLoader`对象、损失函数`criterion`和分类决策阈值`threshold`, 返回五元元组: 平均损失函数、真阴性样本数`tn`、假阳性样本数`fp`、假阴性样本数`fn`、真阳性样本数`tp`.\n- 注意: 模型需要在函数内完成创建, 并以`.to()`方法搬运到正确的计算设备上.\n- [Nesterov动量](https://proceedings.mlr.press/v28/sutskever13.html)是一种通过引入历史梯度信息加速SGD优化算法收敛的技巧. 在算法实践中一般推荐`momentum`取初值为0.5.","metadata":{},"id":"20026739-1e38-4c30-95bd-44ec4ad6be43"},{"cell_type":"code","source":"def train_model_epoch(model, dataloader, optimizer, criterion, log=True):\n    model.train()\n    train_loss = 0\n    num_batches = len(dataloader)\n    for i, (X, y_true) in enumerate(dataloader):\n        optimizer.zero_grad()\n        y_prob = model(X)\n        loss = criterion(y_prob, y_true)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss\n        if log:\n            if i % 100 == 0:\n                print(f\"Batch No. {i}, loss = {loss.item()}\")\n    return (train_loss / num_batches).item()","metadata":{},"execution_count":null,"id":"bfe556e1-2ef2-4e4c-abf4-4e108708c0f9"},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate_model(model, dataloader, criterion, threshold: float=0.5):\n    model.eval()\n    loss, tp, fp, tn, fn = 0, 0, 0, 0, 0\n    num_batches = len(dataloader)\n    for X, y_true in dataloader:\n        y_prob = model(X)\n        loss += criterion(y_prob, y_true)\n        y_pred = (y_prob > threshold)\n        for idx in range(y_true.shape[0]):\n            true, pred = int(y_true[idx].item()), int(y_pred[idx].item())\n            if (true, pred) == (1, 1):\n                tp += 1\n            elif (true, pred) == (1, 0):\n                fn += 1\n            elif (true, pred) == (0, 1):\n                fp += 1\n            else:\n                tn += 1\n    return (loss / num_batches).item(), tn, fp, fn, tp","metadata":{},"execution_count":null,"id":"62074f89-4a52-4f96-be37-fad4ec55c836"},{"cell_type":"code","source":"from typing import Dict, List, Tuple\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\ndef train_model(\n    train_subset, val_subset, config: Dict, num_epochs: int=5,\n    device=\"cpu\", log=True, save=False\n) -> Tuple[List[float], List[float], List[float], List[float]]:\n    ### BEGIN YOUR SOLUTION ###\n    raise NotImplementedError()\n    ### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"id":"a0a427a0-1a07-42ee-8deb-9fc62b483fa7"},{"cell_type":"markdown","source":"$\\quad$完成任务3后, 请**务必**运行下面两个代码块进行检查. 我们将数据集随机拆分为9:1的训练集与测试集, 并做5个周期的训练尝试, 观察对应的损失函数与准确率.","metadata":{},"id":"227d3984-5e3d-4e00-a1b5-0653ac4ce8b2"},{"cell_type":"code","source":"from torch.utils.data import random_split\n\nconfig = {\n    \"kernel_size\": 3, \"num_hiddens\": 1024,\n    \"batch_size\": 8, \"lr\": 0.01,\n}\ntrain_subset, test_subset = random_split(pizza_or_not_dataset, [0.9, 0.1])\ntrain_losses, train_accs, val_losses, val_accs = train_model(train_subset, test_subset, config, log=True, device=device)","metadata":{},"execution_count":null,"id":"1424634b-c297-4330-8612-323178ba90e1"},{"cell_type":"code","source":"train_losses, train_accs, val_losses, val_accs","metadata":{},"execution_count":null,"id":"112ec259-6a43-46b6-955c-bba45072b11a"},{"cell_type":"markdown","source":"## 超参数数值的试验\n\n$\\quad$在正式进行超参数的组合优化之前, 我们先对两个超参数(卷积核、学习率)的意义做更详细的定性讨论. 为此, 我们先定义下述的函数`visualize_learning`, 用于将训练过程中的损失函数与准确率值进行可视化.","metadata":{},"id":"fda09269-2768-4bb3-9489-0afcc7075d0f"},{"cell_type":"code","source":"def visualize_learning(\n    train_losses_collection, train_accs_collection, val_losses_collection, val_accs_collection,\n    mode=\"tune\", labels=None\n):\n    if mode == \"tune\":\n        fig, axes = plt.subplots(2, 2, layout=\"constrained\")\n        for label, train_losses in zip(labels, train_losses_collection):\n            axes[0][0].plot(train_losses, marker=\"^\", label=label)\n        axes[0][0].set_title(\"Train losses\")\n        axes[0][0].set_xlabel(\"Epoch No.\")\n        axes[0][0].set_ylabel(\"Loss\")\n        axes[0][0].legend()\n        for label, val_losses in zip(labels, val_losses_collection):\n            axes[0][1].plot(val_losses, marker=\"^\", label=label)\n        axes[0][1].set_title(\"Validation losses\")\n        axes[0][1].set_xlabel(\"Epoch No.\")\n        axes[0][1].set_ylabel(\"Loss\")\n        axes[0][1].legend()\n        for label, train_accs in zip(labels, train_accs_collection):\n            axes[1][0].plot(train_accs, marker=\"^\", label=label)\n        axes[1][0].set_title(\"Train accuracies\")\n        axes[1][0].set_xlabel(\"Epoch No.\")\n        axes[1][0].set_ylabel(\"Accuracy\")\n        axes[1][0].legend()\n        for label, val_accs in zip(labels, val_accs_collection):\n            axes[1][1].plot(val_accs, marker=\"^\", label=label)\n        axes[1][1].set_title(\"Validation accuracies\")\n        axes[1][1].set_xlabel(\"Epoch No.\")\n        axes[1][1].set_ylabel(\"Accuracy\")\n        axes[1][1].legend()\n    else:\n        fig, (ax1, ax2) = plt.subplots(1, 2)\n        ax1.plot(train_losses_collection, label=\"train\")\n        ax1.plot(val_losses_collection, label=\"test\")\n        ax1.set_title(\"Losses on train/test dataset\")\n        ax1.set_xlabel(\"Epoch No.\")\n        ax1.set_ylabel(\"Loss\")\n        ax1.legend()\n        ax2.plot(train_accs_collection, label=\"train\")\n        ax2.plot(val_accs_collection, label=\"test\")\n        ax2.set_title(\"Accuracies on train/test dataset\")\n        ax2.set_xlabel(\"Epoch No.\")\n        ax2.set_ylabel(\"Accuracy\")\n        ax2.legend()","metadata":{},"execution_count":null,"id":"ca0de731-a709-4754-a423-0de97dc8cb32"},{"cell_type":"markdown","source":"$\\quad$**任务4**: 分别讨论下述超参数对模型性能的影响.\n- **任务4.1**: 其他条件不变, 取卷积核`kernel_size`分别为1、3、5;\n- **任务4.2**: 其他条件不变, 取学习率`lr`分别为0.001、0.01、0.1.","metadata":{},"id":"9fabfd54-2632-4e7f-8049-86a369ea1c62"},{"cell_type":"markdown","source":"$\\quad$运行下述代码块, 观察结果, 在对应答题区解释你关于卷积核的发现.\n- 提示: 卷积核大小如何影响空间信息的提取能力、如何影响模型参数的规模?","metadata":{},"id":"e0fbb195-4c4c-4348-976e-b1607026af40"},{"cell_type":"code","source":"kernel_size_collection = (1, 3, 5)\nlabels = []\ntrain_losses_collection, train_accs_collection, val_losses_collection, val_accs_collection = [], [], [], []\n\nfor kernel_size in kernel_size_collection:\n    config[\"kernel_size\"] = kernel_size\n    labels.append(f\"{kernel_size}x{kernel_size} kernel\")\n    train_losses, train_accs, val_losses, val_accs = train_model(train_subset, test_subset, config, log=False, device=device)\n    train_losses_collection.append(train_losses)\n    train_accs_collection.append(train_accs)\n    val_losses_collection.append(val_losses)\n    val_accs_collection.append(val_accs)\n\nvisualize_learning(\n    train_losses_collection, train_accs_collection, val_losses_collection, val_accs_collection,\n    labels=labels\n)\n\n### 任务4.1答题区(另起一行时请记得加注释符号#) ###\n### BEGIN YOUR SOLUTION ###\n#\n### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"id":"b5ff6878-c6d8-41fa-b00e-8cf3a8faf99c"},{"cell_type":"markdown","source":"$\\quad$运行下述代码块, 观察结果, 在对应答题区解释你关于学习率的发现.\n- 提示: 梯度下降的步长过大或过小会导致怎样的后果?","metadata":{},"id":"cd621eda-2f0c-4f9d-abc0-b4edd849d1c6"},{"cell_type":"code","source":"config[\"batch_size\"] = 8\nlr_collection = (10 ** n for n in (-3, -2, -1))\nlabels = []\ntrain_losses_collection, train_accs_collection, val_losses_collection, val_accs_collection = [], [], [], []\n\nfor lr in lr_collection:\n    config[\"lr\"] = lr\n    train_losses, train_accs, val_losses, val_accs = train_model(train_subset, test_subset, config, log=False, device=device)\n    labels.append(f\"lr = {lr}\")\n    train_losses_collection.append(train_losses)\n    train_accs_collection.append(train_accs)\n    val_losses_collection.append(val_losses)\n    val_accs_collection.append(val_accs)\n\nvisualize_learning(\n    train_losses_collection, train_accs_collection, val_losses_collection, val_accs_collection,\n    labels=labels\n)\n\n### 任务4.2答题区(另起一行时请记得加注释符号#) ###\n### BEGIN YOUR SOLUTION ###\n#\n### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"id":"ba4554b8-85ee-46ba-a5ab-8e55f9527306"},{"cell_type":"markdown","source":"## 超参数的组合优化\n\n$\\quad$现在, 我们使用`ray`库完成超参数优化.\n\n$\\quad$**任务5**: 完成可训练函数`trainable`的编写, 按照`ray`库的要求, 只接受训练配置字典作为唯一的输入. 要求: 根据已给出的`splits`索引列表, 实现训练集上的5折交叉验证, 并以[`ray.train.report`](https://docs.ray.io/en/latest/train/api/doc/ray.train.report.html#ray-train-report)函数报告平均(最后一个训练周期上的)的平均验证损失`val_loss`与平均验证准确率`val_acc`.\n\n### 提示\n- 如果希望具有可复现性, 可以在你的函数开头加上[`train.torch.enable_reproducibility()`](https://docs.ray.io/en/latest/train/user-guides/reproducibility.html#reproducibility).\n- 用好前面已经写好的`train_model()`函数.","metadata":{},"id":"77add4ec-3b1e-4410-833b-cd36c7439fe9"},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom ray import train\nimport ray.train.torch\n\nn_splits = 5\nsplits = list(KFold(n_splits=n_splits, shuffle=True, random_state=42).split(train_subset))\n\ndef trainable(config):\n    ray.train.torch.enable_reproducibility()\n    ### BEGIN YOUR SOLUTION ###\n    raise NotImplementedError()\n    ### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"id":"c3ed26ce-52be-45c4-a28b-ff076580bc33"},{"cell_type":"markdown","source":"$\\quad$完成任务5后, 请**务必**运行下述代码块, 完成超参数优化的过程. 我们将取10个训练周期, 并进行6组尝试, 以“验证集损失函数值最小”作为超参数的选择标准.\n- **注意**: 机器配置`{\"cpu\": 4, \"gpu\": 0.3}`是对应`c12_m46_1 * NVIDIA GPU B`机器的, 这将每次同时运行3组超参数配置的尝试(每组尝试对应4 CPU、0.3 GPU). 如果你是在`c2_m4_cpu`上运行, 则应改为`{\"cpu\": 2, \"gpu\": 0}`. 如果是在本地机器上运行, 则需要根据具体的机器配置自行决定. 可通过[`ray.cluster_resources()`](https://docs.ray.io/en/latest/ray-core/api/doc/ray.cluster_resources.html#ray-cluster-resources)方法查看你的计算资源.\n- 如果受限于计算资源无法完成调参过程, 你可以直接使用前面给出的`config`字典的初值进行后续训练(注意将学习率`lr`调回0.01), 但请增设一个代码块输出`ray.cluster_resources()`的运行结果, 不会因此而影响作业得分.","metadata":{},"id":"1371dd00-91ac-4f47-bf8d-1191ffb8b361"},{"cell_type":"code","source":"from ray import tune\nfrom ray.tune.schedulers import ASHAScheduler\n\nscheduler = ASHAScheduler(max_t=10, grace_period=5)\n\ntune_config = tune.TuneConfig(\n    metric=\"val_loss\", mode=\"min\",\n    scheduler=scheduler,\n    num_samples=6,\n)\n\nparam_space = {\n    \"lr\": tune.loguniform(1e-2, 1e-1),\n    \"num_hiddens\": tune.choice([512, 1024]),\n    \"kernel_size\": tune.choice([3, 5]),\n    \"batch_size\": tune.choice([8, 16, 32])\n}\n\ntuner = tune.Tuner(\n    trainable=tune.with_resources(\n        tune.with_parameters(trainable),\n        # resources={\"cpu\": 2, \"gpu\": 0}\n        resources={\"cpu\": 4, \"gpu\": 0.3}\n    ),\n    tune_config=tune_config,\n    param_space=param_space\n)\n\nresults = tuner.fit()","metadata":{},"execution_count":null,"id":"4920e1de-3166-4deb-b16c-c4c984db373f"},{"cell_type":"markdown","source":"$\\quad$优化完成后, 请**务必**运行下述代码块, 获得最优超参数配置.","metadata":{},"id":"fb09d05d-4d96-42df-b66a-0ed6a4aa783a"},{"cell_type":"code","source":"best_result = results.get_best_result(\"val_loss\", \"min\")\nbest_result.config","metadata":{},"execution_count":null,"id":"72039f25-78ee-4b97-a7cd-7da38861842d"},{"cell_type":"markdown","source":"# 模型训练与预测\n\n$\\quad$最后, 我们以最优超参数配置在全体训练集上训练10个周期, 并将训练好的模型保存, 作新一轮的评估.\n\n$\\quad$**任务6**: 运行下述4个代码块, 输出模型的准确率、查准率、查全率. 看一看我们的披萨分类器从众多食物中区分出披萨的能力如何🥳!","metadata":{},"id":"98b1c070-0b13-4d00-99ba-9b6f10d27b96"},{"cell_type":"code","source":"train_losses, train_accs, test_losses, test_accs = train_model(\n    train_subset, test_subset, config=best_result.config, num_epochs=10,\n    log=True, save=True, device=device\n)","metadata":{},"execution_count":null,"id":"7ec1beaf-75da-4e99-a9dd-372e71b191e7"},{"cell_type":"code","source":"visualize_learning(train_losses, train_accs, test_losses, test_accs, mode=\"train\")","metadata":{},"execution_count":null,"id":"4cc288fa-36a7-41f0-b3c9-3165f68db039"},{"cell_type":"code","source":"def report_metrics(tn, fp, fn, tp):\n    return {\n        \"accuracy\": (tn + tp) / (tn + fp + fn + tp),\n        \"precision\": tp / (tp + fp),\n        \"recall\": tp / (tp + fn)\n    }","metadata":{},"execution_count":null,"id":"3cde09ff-8aba-4dce-997a-19c9976df6f0"},{"cell_type":"code","source":"model = PizzaOrNotModel(\n    kernel_size=best_result.config[\"kernel_size\"],\n    num_hiddens=best_result.config[\"num_hiddens\"],\n).to(device)\nmodel.load_state_dict(torch.load(\"PizzaOrNotModel.pt\"))\n_, tn, fp, fn, tp = evaluate_model(model, DataLoader(test_subset), criterion=nn.BCELoss())\nreport_metrics(tn, fp, fn, tp)","metadata":{},"execution_count":null,"id":"f67ab26b-cdb2-4b2c-86c4-384d3deeaeb6"}],"metadata":{"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"}},"nbformat":4,"nbformat_minor":5}