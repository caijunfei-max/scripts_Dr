{"metadata":{"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 背景概述\n\n$\\quad$**对映选择性**(enantioselectivity)是有机化学重要的研究主题之一. 在有机反应中, 手性催化剂的对映选择性往往与反应过渡态中一些重要的**非共价相互作用**(non-covalent interactions, NCIs)有关. 以[Birman等](https://pubs.acs.org/doi/10.1021/ja0491477)报道的酰基转移反应为例:\n\n![alt image.png](https://bohrium.oss-cn-zhangjiakou.aliyuncs.com/article/17993/6691c6d5302140c582b7343f24173c5d/bSUHb1WG1pR3NNhIsLuhDA.png)\n\n在Birman等假设的机理中, 手性催化剂的对映选择性由$\\pi$-$\\pi$堆积或$\\pi$-阳离子堆积作用介导, 特定手性的过渡态因位阻作用导致两个芳环不平行, 不利于堆积作用的形成.\n\n![alt image.png](https://bohrium.oss-cn-zhangjiakou.aliyuncs.com/article/17993/e1edd4976ba44a58b0952756aeb950fd/RDAnx-oUTRUK7MbgTA6CPw.png)\n\n$\\quad$本次上机作业中, 我们将以线性回归模型定量地探索所用手性催化剂的性质对对映选择性的影响, 试图揭示: (1) 哪些性质参数会影响对映选择性? (2) 如何优化性质参数可以提升对映选择性 (例如减少还是增加某参数)? 为此, 我们将考察如下图所示的模型体系:\n\n![alt image.png](https://bohrium.oss-cn-zhangjiakou.aliyuncs.com/article/17993/ad92a2cb3d0040ffbde82802641d5a39/uz3674Qv_rCWWOAd9DpFTw.png)\n\n其中, 底物的芳香环(**A**, **a**, **b**)按照特定的几何约束条件与催化剂(**D**, **c**, **d**)排列成复合物, 而芳环与底物的其余分子骨架(包含醇羟基和烷基)在图中箭头所示位置相连.\n\n- 参考文献: [J. Am. Chem. Soc. 2017, 139, 20, 6803–6806](https://pubs.acs.org/doi/10.1021/jacs.7b02311)","metadata":{},"id":"f9950258-f41e-47fe-8a04-5fe22adf4917"},{"cell_type":"markdown","source":"# 数据探索与清洗","metadata":{},"id":"2170e221-cd75-4a1f-a350-175637af4e14"},{"cell_type":"markdown","source":"## 数据的初步探索\n\n$\\quad$在数据集`nci_birman.csv`中, 包含如下三组(用作特征的)参数:\n- $\\pi$-$\\pi$堆积作用参数: `d_pi_d`, `d_pi_D`, `e_pi_d`, `e_pi_D`. 根据特定的电子结构计算方法(B97-D/def2TZVP水平), 对复合物进行几何优化, 给出几何结构信息与互作能(复合物能量减去各组分能量和). 其中:\n  - 每组复合物中, 底物芳环由于具体朝向的不同, 存在2种可能构象(比如下图的例子), 分别以后缀`_d`和`_D`作区分;\n    ![alt image.png](https://bohrium.oss-cn-zhangjiakou.aliyuncs.com/article/17993/842ed157585c4e4a8ba62ad2b91cf582/tUoBI8UPrb1b5S2Z1R3WHw.png)\n  - 在计算中, 对底物与催化剂分子的两个芳环施加约束条件, 使二者完全“正对彼此”(环平面平行, 且两环中心的连线与环平面垂直). 此时, 我们找到使电子能量(前缀`e_`, 单位kcal/mol)最低的、也就是使复合物最稳定的环间距(前缀`d_`, 单位Å)\n- 烷基几何参数: `L_Alk`, `B1_Alk`, `B5_Alk`, 分别代表长度、最大宽度、最小宽度.\n- 芳环几何参数: `L_Ar`, `B1_Ar`, `B5_Ar`, 分别代表长度、最大宽度、最小宽度.\n后两组参数称为[**Sterimol参数**](https://en.wikipedia.org/wiki/Sterimol_parameter), 其具体含义可从下图中做简单的理解:\n\n![alt image.png](https://bohrium.oss-cn-zhangjiakou.aliyuncs.com/article/17993/842ed157585c4e4a8ba62ad2b91cf582/zpobYlZXNb5KHS_mwjLSBA.png)\n\n$\\quad$我们的线性回归模型将以上述参数作为特征(在化学信息学中, 这些特征也常称为**描述符**, descriptor), 试图预测特定催化剂针对特定底物的对映选择性. 在数据集中, 选择性以**对映比**$er$描述, 这是一个实验可测的量. 通过热力学公式, 我们可以将其与两种对映体的活化自由能之差$\\Delta\\Delta G^\\ddagger$之间建立定量联系:\n\n$$\n\\Delta\\Delta G^\\ddagger = -RT\\ln{(er)}.\n$$","metadata":{},"id":"4ba3f5b5-1109-44f6-9a85-8c89d6aaeda1"},{"cell_type":"code","source":"import pandas as pd\nnci_birman = pd.read_csv(\"/bohr/MLInChem-1za4/v1/nci_birman.csv\", sep=\"\\t\")\nnci_birman.iloc[:5, :]","metadata":{},"execution_count":null,"outputs":[],"id":"7d8cb563-eca0-48b4-ab0d-a6c30a9e00da"},{"cell_type":"markdown","source":"## 数据的清洗与加工\n\n$\\quad$对于堆积相互作用参数, 我们不妨对其进行降维: 取两个可能构象`_d`和`_D`的参数加权和:\n$$\\begin{aligned}\nD\\pi_\\mathrm{w} &:= c_\\mathrm{d}D\\pi_\\mathrm{d} + c_\\mathrm{D}D\\pi_\\mathrm{D},\\\\\nE\\pi_\\mathrm{w} &:= c_\\mathrm{d}E\\pi_\\mathrm{d} + c_\\mathrm{D}E\\pi_\\mathrm{D},\n\\end{aligned}$$\n其中, 权重$c_\\mathrm{X}(\\mathrm{X} = \\mathrm{d}, \\mathrm{D})$取为(按电子能量计算的)Boltzmann因子:\n$$\nc_\\mathrm{X} = \\frac{\n\\exp{\\left(-\\frac{E\\pi_\\mathrm{X}}{RT}\\right)}\n}{\n\\exp{\\left(-\\frac{E\\pi_\\mathrm{d}}{RT}\\right)} + \\exp{\\left(-\\frac{E\\pi_\\mathrm{D}}{RT}\\right)}.\n}\n$$","metadata":{},"id":"e2aa56d0-1515-4a97-a767-f009a3090a75"},{"cell_type":"markdown","source":"**任务1**: 对数据`nci_birman`进行进一步加工处理.\n- 在函数`prepare_data()`中, 输入:\n  - 直接读取自`csv`的原始数据集`in_df`;\n  - 用于进行加权和与$\\Delta \\Delta G^\\ddagger$计算的温度`temperature`.\n- 返回: 处理好的特征和标签.\n- 特征为`pd.DataFrame`格式, 包括:\n  - 降维后的(加权)参数$D\\pi_\\mathrm{w}, E\\pi_\\mathrm{w}$, 以及二者的交叉项(乘积)$D\\pi_\\mathrm{w}E\\pi_\\mathrm{w}$, 分别命名为`d_pi_w`, `e_pi_w`与`de_pi_w`;\n  - 所有原有的Sterimol几何参数, 名称不变.\n- 标签为`pd.Series`格式, 为自由能差$\\Delta \\Delta G^\\ddagger = -RT\\ln{(er)}$, 单位取为kcal/mol, 命名为`delta_delta_G`. 这里给出单位换算因子: 1 kcal/mol = 4.184 kJ/mol.","metadata":{},"id":"46fe9e13-dd30-4000-8c09-3356cc14fe42"},{"cell_type":"code","source":"from typing import Tuple\nimport numpy as np\n\nR = 8.314    # ideal gas constant\nkcal_to_kj = 4.184    # unit conversion\n\ndef prepare_data(in_df: pd.DataFrame, temperature: float=298.0) -> Tuple[pd.DataFrame, pd.Series]:\n    ### BEGIN YOUR SOLUTION ###\n    \n    ### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"outputs":[],"id":"e3e84899-00de-47d9-88ce-5ea0d3fe38a0"},{"cell_type":"markdown","source":"$\\quad$完成该函数后, 请**务必**运行下面的代码块先做初步检查.","metadata":{},"id":"b51dce92-431e-43e1-8c04-a3f0008c60eb"},{"cell_type":"code","source":"X, y_true = prepare_data(nci_birman)\nX.iloc[:5, :], y_true[:5]","metadata":{},"execution_count":null,"outputs":[],"id":"ca9ac812-5f50-4b1f-a3be-a7a7fdd9b018"},{"cell_type":"markdown","source":"$\\quad$完成初步检查后, 可以运行下面的代码块对该函数进行测试. 测试通过情况将关系到该任务的得分. **请勿修改该代码块中的任何内容**.","metadata":{},"id":"2d27752f-25f9-45a6-a7f0-579eb7fce3bf"},{"cell_type":"code","source":"### CAUTION: DO NOT MODIFY THIS CELL. ###\n\ntest_in_df = pd.concat([\n    pd.DataFrame({\n        \"d_pi_d\": [4.89, 4.91, 6.48, 7.00],\n        \"d_pi_D\": [7.00, 7.21, 7.22, 7.20],\n        \"e_pi_d\": [-3.48, -2.98, -1.80, -1.45],\n        \"e_pi_D\": [-1.48, -2.00, -1.96, -2.26]\n    }),\n    nci_birman.iloc[:4, 4:]\n], axis=1)\n\ntest_labels = np.array([2.409283, 2.009314, 1.939568, 1.770392])\ntest_weighted_features = np.array([\n    [4.959643, -3.413988, -16.932160],\n    [5.279007, -2.822771, -14.901427],\n    [6.899685, -1.890743, -13.045529],\n    [7.159408, -2.095601, -15.003264]\n])\n\ndef test_prepare_data_names(in_df):\n    X_, y_true_ = prepare_data(in_df)\n    assert set(X.columns) == {\"d_pi_w\", \"e_pi_w\", \"de_pi_w\", \"L_Alk\", \"B1_Alk\", \"B5_Alk\", \"L_Ar\", \"B1_Ar\", \"B5_Ar\"}, \"wrong column names.\"\n    assert y_true_.name == \"delta_delta_G\", \"wrong label name.\"\n\ndef test_prepare_data_labels(in_df, labels):\n    _, y_true_ = prepare_data(in_df)\n    np.testing.assert_allclose(\n        y_true_, labels, rtol=1.0e-3,\n        err_msg=\"wrong label values.\"\n    )\n\ndef test_prepare_data_weighted_features(in_df, weighted_features):\n    X_, _ = prepare_data(in_df)\n    np.testing.assert_allclose(\n        X_.loc[:, [\"d_pi_w\", \"e_pi_w\", \"de_pi_w\"]], weighted_features, rtol=1.0e-3,\n        err_msg=\"wrong weighted feature values.\"\n    )\n    \ntry:\n    test_prepare_data_names(test_in_df)\n    print(\"names: PASSED\")\nexcept Exception as err:\n    print(err)\n\ntry:\n    test_prepare_data_labels(test_in_df, test_labels)\n    print(\"labels: PASSED\")\nexcept Exception as err:\n    print(err)\n\ntry:\n    test_prepare_data_weighted_features(test_in_df, test_weighted_features)\n    print(\"weighted features: PASSED\")\nexcept Exception as err:\n    print(err)","metadata":{},"execution_count":null,"outputs":[],"id":"dcf08e29-0593-4dd5-b825-9979ebaa5496"},{"cell_type":"markdown","source":"## 拆分与归一化\n$\\quad$原数据没有直接分出训练集和测试集, 我们可以用[`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn-model-selection-train-test-split)对数据集进行手动拆分.\n\n$\\quad$**任务2**: 将28个样本先按照23:5的份额划分训练集与测试集, 再在**各个数据集上**分别对特征作均值-方差归一化:\n\n$$\nx_n' := \\frac{x_n - \\mathrm{Mean}_{n=1}^N(x)}{\\mathrm{Std}_{n=1}^N(x)},\\,n=1,\\dots,N,\n$$\n\n返回(归一化后的)训练集与测试集. 注意: **测试集上归一化时, 正确的做法是使用训练集上算出的均值和方差, 而非在测试集上重新计算**.\n\n- **任务2.1**: 完成函数`split_and_normalize()`的编写, 输入:\n  - 原始数据集的特征`X`与标签`y_true`;\n  - 测试集大小`test_size`(默认为5).\n- 返回拆分好的`X_train`, `X_test`, `y_true_train`, `y_true_test`, 其中, `X_train`与`X_test`进行了归一化处理. **为了和`StandardScaler`保持统一, 请确保返回的四个值均为`np.array`格式**.\n- **任务2.2**: 在以下代码块的注释区回答问题: 为什么均值-方差归一化需要在训练集和测试集上分开进行? 如果先归一化再拆分, 会导致什么后果?","metadata":{},"id":"92e90e17-ac69-4d21-9f90-23b620a1d2a8"},{"cell_type":"markdown","source":"### 提示\n- 归一化(在`sklearn`中叫做**标准化**, standardization)既可以像上机实习1演示的那样手动计算, 也可以通过函数[`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)实现.\n  - **注意**: 如果自己用`pandas`库计算`mean`和`std`, 请设置计算`std`时的参数`ddof=0`. 这是`StandardScaler`方法的计算原则.\n- 警惕机器学习模型在数据集上“作弊”.","metadata":{},"id":"33e38fad-1720-44b5-8c1c-eb170b5269d6"},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ndef split_and_normalize(\n    X: pd.DataFrame, y_true: pd.Series, test_size: int=5\n) -> Tuple[np.array, np.array, np.array, np.array]:\n    ### BEGIN YOUR SOLUTION ###\n    \n    ### END YOUR SOLUTION ###\n\n### 任务2.2答题区(另起一行时请记得加注释符号#) ###\n### BEGIN YOUR SOLUTION ###\n#\n### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"outputs":[],"id":"a22d4a1c-6630-4437-bffe-6a1f67dce14a"},{"cell_type":"markdown","source":"$\\quad$完成该函数后, 请**务必**运行下面的代码块先做初步检查.","metadata":{},"id":"97e75f5a-37bf-49ff-913d-e8252fb425b5"},{"cell_type":"code","source":"X_train, X_test, y_true_train, y_true_test = split_and_normalize(X, y_true)\nX_train.shape, X_test.shape, y_true_train.shape, y_true_test.shape, X_train[:5, :]","metadata":{},"execution_count":null,"outputs":[],"id":"0842425d-e570-459c-9424-94e78098df57"},{"cell_type":"markdown","source":"$\\quad$完成初步检查后, 可以运行下面的代码块对该函数进行测试. 测试通过情况将关系到该任务的得分. **请勿修改该代码块中的任何内容**.","metadata":{},"id":"dec0cf9a-af2b-4789-a1bf-f68e96a2c281"},{"cell_type":"code","source":"n_samples, n_features, test_size = 40, 9, 7\ntest_X = np.random.randn(n_samples, n_features)\ntest_y_true = np.random.randn(n_samples)\n\ndef test_split_and_normalize_shapes(X, y_true):\n    X_train_, X_test_, y_true_train_, y_true_test_ = split_and_normalize(X, y_true, test_size=test_size)\n    assert (X_train_.shape, X_test_.shape) == ((n_samples - test_size, 9), (test_size, 9)), \"wrong X shape.\"\n    assert (*y_true_train_.shape, *y_true_test_.shape) == (n_samples - test_size, test_size), \"wrong y_true shape.\"\n\ndef test_split_and_normalize_normalized(X, y_true):\n    X_train_, X_test_, _, _ = split_and_normalize(X, y_true)\n    np.testing.assert_allclose(\n        X_train_.mean(axis=0), np.zeros(n_features), atol=1.0e-5,\n        err_msg=\"invalid X_train normalization: non-zero mean.\"\n    )\n    np.testing.assert_allclose(\n        X_train_.std(axis=0), np.ones(n_features), rtol=1.0e-3,\n        err_msg=\"invalid X_train normalization: non-unit std.\"\n    )\n\ntry:\n    test_split_and_normalize_shapes(test_X, test_y_true)\n    print(\"shapes after split: PASSED\")\nexcept Exception as err:\n    print(err)\n\ntry:\n    test_split_and_normalize_normalized(test_X, test_y_true)\n    print(\"normalization: PASSED\")\nexcept Exception as err:\n    print(err)","metadata":{},"execution_count":null,"outputs":[],"id":"c5a49427-8232-489e-b85b-cea7fa833024"},{"cell_type":"markdown","source":"# 模型训练与评估\n\n$\\quad$我们在9个特征与23个训练样本上训练一个线性回归模型, 并评估其在5个测试样本上的预测表现.\n\n$\\quad$**任务3**: 搭建模型, 完成训练与评估.\n\n- **任务3.1**: 完成函数`train_model()`的编写. 输入:\n  - 训练集`X_train, y_true_train`.\n- 返回一个训练好的线性回归模型[`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn-linear-model-linearregression).\n- **任务3.2**: 编写函数`evaluate_model()`, 实现预测图、$R^2$与RMSE值的报告(作图用的函数`plot_prediction()`已经给出). 输入:\n  - 模型`model`与数据集`X`, `y_true`;\n  - 评估模式`mode`, 可在`plot`和`metrics`中二选一, 如果传入`plot`则作预测图(不返回任何内容), 如果传入`metrics`则返回RMSE与$R^2$值.\n- **任务3.3**: 调用你编写的函数`evaluate_model()`, 完成下述任务:\n  - 将训练集上的预测图保存为文件`pred.png`, 以备提交;\n  - 将测试集上的RMSE值与$R^2$值打印出来.","metadata":{},"id":"198fe9af-666c-4d2a-a83c-38e44ddc07cf"},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\ndef train_model(X_train, y_true_train) -> object:\n    ### BEGIN YOUR SOLUTION ###\n    \n    ### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"outputs":[],"id":"6b190054-c12a-46f3-b855-6e3da1509121"},{"cell_type":"markdown","source":"$\\quad$完成任务3.1后, 请**务必**运行下面的代码块做初步检查: 输出的在训练集上的RMSE值应当与0很接近.","metadata":{},"id":"920a1d43-4276-49de-9401-e3a3d09be445"},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nlr = train_model(X_train, y_true_train)\nmean_squared_error(lr.predict(X_train), y_true_train, squared=False)","metadata":{},"execution_count":null,"outputs":[],"id":"f85026d8-2b07-4c42-8c3f-7e5955b86079"},{"cell_type":"markdown","source":"$\\quad$检查完成后, 你可以继续完成任务3.2: 结合给出的函数`plot_prediction()`(已经给出, 取自上机实习1), 编写函数`evaluate_model()`.","metadata":{},"id":"cb121924-6175-4cf0-bfdc-90cb437577e9"},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom sklearn.metrics import r2_score\n\ndef plot_prediction(y_true: np.array, y_pred: np.array):\n    r2 = r2_score(y_true, y_pred)\n    # text annotation setup\n    plt.title(r\"True values vs predicted values ($R^2$ = \" + f\"{r2:.4f}\" + \")\")\n    plt.xlabel(\"True values\")\n    plt.ylabel(\"Predicted values\")\n    # plot the scatter and line\n    plt.scatter(y_true, y_pred, c=\"red\", marker=\"o\")\n    plt.plot(y_true, y_true, \"b--\")\n    # show the plot!\n    plt.show()","metadata":{},"execution_count":null,"outputs":[],"id":"9c49c72e-be69-492a-abb8-88657dbbfdf4"},{"cell_type":"code","source":"def evaluate_model(model, X, y_true, mode: str):\n    ### BEGIN YOUR SOLUTION ###\n    \n    ### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"outputs":[],"id":"af33ccdf-0d36-46fd-9c40-4e0f24301970"},{"cell_type":"markdown","source":"$\\quad$完成该函数后, 你可以继续完成任务3.3: 运行下面的代码块. 我们先在训练集上作出预测图, 再报告测试集上的RMSE与$R^2$.","metadata":{},"id":"31cf3a2b-fe41-4e0b-b8fe-320e26b95461"},{"cell_type":"code","source":"evaluate_model(lr, X_train, y_true_train, mode=\"plot\")\nRMSE, r2 = evaluate_model(lr, X_test, y_true_test, mode=\"metrics\")\nprint(f\"RMSE: {RMSE}\")\nprint(f\"r2: {r2}\")","metadata":{},"execution_count":null,"outputs":[],"id":"355174e3-1f8c-4e05-b9f9-cc71018f05e2"},{"cell_type":"markdown","source":"$\\quad$**选做任务**: 所选参数是足够合理的吗? 一方面, 实验数据本身可能就带有噪声; 另一方面, 所选取的几何参数数目还是过多了. 事实上, 若想进一步对特征进行降维(或挑选), 还可以有很多策略, 例如:\n\n- 主元分析法(PCA, 将在后续课程学到).\n- $L_1$-正则化. 理论课已经讲过, $L_1$-范数约束相比于$L_2$-范数约束更易产生稀疏解, 我们借助正则化强度的控制, 可以让很多参数变为0, 对应的那些分量就相应被舍弃, 达到**特征选择**(feature selection)的目的.\n- 根据各个特征可以解释的数据方差大小进行特征选择, 详情可阅读[`sklearn.feature_selection`](https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection)模块的官方文档.\n\n你可以选择在下面的代码块中自由实践你感兴趣的特征选择方法, 并在注释的答题区中给出你的讨论.","metadata":{},"id":"0d5d613e-4eaa-4958-b681-abbb07ca7818"},{"cell_type":"code","source":"\n\n### 选做任务答题区(另起一行时请记得加注释符号#) ###\n### BEGIN YOUR SOLUTION ###\n#\n### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"outputs":[],"id":"3e9c67ea-fe7e-49f8-b116-59b7e39465fc"},{"cell_type":"markdown","source":"# 结果分析","metadata":{},"id":"cdda1272-69a0-429e-8d68-4b5d78a93197"},{"cell_type":"markdown","source":"$\\quad$**任务4**: 运行下面的代码块, 根据参数正负, 考察各个因素对对映选择性的影响, 在注释的答题区中写下你的分析.\n- $\\pi$-$\\pi$堆积作用如何影响对映选择性? (从几何结构与能量两方面考虑) 这符合你的直觉吗?\n- 烷基的几何参数如何影响对映选择性? 和芳基几何参数相比, 总体看, 谁的影响更大?","metadata":{},"id":"98f7f847-28b5-49e0-8b61-7412e1c73467"},{"cell_type":"markdown","source":"### 提示\n- $\\Delta \\Delta G^\\ddagger$越大, 表明两种对映异构体的动力学活性相差越大, 于是对映选择性越好.\n- 你可能会得到一些反直觉的结果, 但这是模型过拟合(特征数目过多)导致的问题, 请如实地反映输出结果, 并写出你的疑惑.","metadata":{},"id":"f2e4f745-47c7-4d28-b429-7c0eec216e5f"},{"cell_type":"code","source":"lr.coef_\n\n### 任务4答题区(另起一行时请记得加注释符号#) ###\n### BEGIN YOUR SOLUTION ###\n#\n### END YOUR SOLUTION ###","metadata":{},"execution_count":null,"outputs":[],"id":"6528bcd1-fecf-4087-83ce-9153cdf34eda"}]}